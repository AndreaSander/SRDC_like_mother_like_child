select(c(strategy, lang_status, fre_exp, eng_exp))
#french exposure
pwc_fre_exp_g1 <- for_t_tests_g1 %>%
pairwise_t_test(
fre_exp~strategy, pool.sd = FALSE,
p.adjust.method = "bonferroni"
)
pwc_fre_exp_g1
#english exposure
pwc_eng_exp_g1 <- for_t_tests_g1 %>%
pairwise_t_test(
eng_exp~strategy, pool.sd = FALSE,
p.adjust.method = "bonferroni"
)
pwc_eng_exp_g1
one_maj_data<- final_data_strat %>%
filter(lang_status == "one_maj")
#80 observations
prop_strategy_group2<-one_maj_data %>%
group_by(strategy) %>%
tally() %>%
mutate(prop = n/sum(n))
print(prop_strategy_group2)
#the cell sizes are a bit small... but it does give a different story about which strategies are the most used than when both languages are majority
#get the minority language exposure
one_maj_data<- one_maj_data %>%
mutate(min_exp = case_when (!(l1 %in% c("French", "English"))& l2 %in% c("French", "English") ~ exp_l1,
!(l2 %in% c("French", "English")) & l1 %in% c("French", "English") ~ exp_l2,
TRUE ~ 0
))
for_t_tests_g2<- one_maj_data %>%
select(c(strategy, lang_status, fre_exp, eng_exp, min_exp))
#french exposure
pwc_fre_exp_g2 <- for_t_tests_g2 %>%
pairwise_t_test(
fre_exp~strategy, pool.sd = FALSE,
p.adjust.method = "bonferroni"
)
pwc_fre_exp_g2
#english exposure
pwc_eng_exp_g2 <- for_t_tests_g2 %>%
pairwise_t_test(
eng_exp~strategy, pool.sd = FALSE,
p.adjust.method = "bonferroni"
)
pwc_eng_exp_g2
#minority exposure
pwc_min_exp_g2 <- for_t_tests_g2 %>%
pairwise_t_test(
min_exp~strategy, pool.sd = FALSE,
p.adjust.method = "bonferroni"
)
pwc_min_exp_g2
m1 <- lmer(exp_l1 ~ strategy + (1|anon_baby_id), data=final_data_strat) #can't with unique id, just anon. To check?
summary(m1)
#some significant effects by strategy.
#quite a bit of variance from the by-subject random intercept = balacedeness has to do also with individual variability than langauge strategy.
#take out the single parent language
#Maybe collapse the OPOL groups?
m1.1 <- lmer(exp_l1 ~ strategy + lang_status + (1|anon_baby_id), data=final_data_strat)
summary(m1.1)
#L1 is many language code everything relative to French as the official language.
m1.2 <- lmer(exp_l1 ~ strategy * lang_status + (1|anon_baby_id), data=final_data_strat)
summary(m1.2)
anova(m1, m1.1) #significantly different so langauge status matters but is it due to the monolinguals?
test<- lmer(exp_l1 ~ lang_status + (1|anon_baby_id), data=final_data_strat)
summary(test) #maybe monolinguals are driving the effect. Which makes sense because ofc monolinguals are unbalanced.
#prediction of French exposure
m2 <- lmer(fre_exp ~ strategy + (1|anon_baby_id), data=final_data_strat)
m2.2<- lmer(fre_exp ~ strategy * lang_status + (1|anon_baby_id), data=final_data_strat)
summary(m2.2)
summary(m2)
#Both parents bilingual and opol-strict marginally
#Look at heritage language speakers and look at the french exposure.
#visualization more similar to analyses. Mean l1 exposure by strategy l1 exp in y.
#Do we just want to do t-tests instead .. order the strategies by how much l1 exposure they give you. And then heritage vs non heritage.
for_t_tests<- final_data_strat %>%
select(c(strategy, lang_status, fre_exp, exp_l1))
#Order l1 amount of exposure by strategy
l1_by_strategy <- for_t_tests %>%
select(c(strategy, exp_l1)) %>%
group_by(strategy) %>%
summarise(mean(exp_l1))
#French exposure
fre_by_strategy <- for_t_tests %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
summarise(mean(fre_exp))
#Pairwise t test comparisons for all the strategies against amount of l1 exposure. Bonferroni corrected p for multiple comparisons.
pwc_exp_l1 <- for_t_tests %>%
pairwise_t_test(
exp_l1~strategy, pool.sd = FALSE,
p.adjust.method = "bonferroni"
)
pwc_exp_l1
#Pairwise t test comparisons for all the strategies against amount of french exposure. Bonferroni corrected p for multiple comparisons.
pwc_fre_exp <- for_t_tests %>%
pairwise_t_test(
fre_exp~strategy, pool.sd = FALSE,
p.adjust.method = "bonferroni"
)
pwc_fre_exp
#langauge status
t.test(fre_exp~lang_status, data = for_t_tests, subset = lang_status %in% c("maj","min"),  mu=0, conf.level = 0.95, paired=F) #If you speak a majority langauge you are more likely to have more fre exp
View(final_data_strat)
library(here)
library(tidyverse)
library(dplyr)
library(lme4)
library(lmerTest)
library(rstatix)
library(broom)
library(janitor)
load(here("anonymized_data/final_merged_data.Rda"))
library(lubridate)
library(sparkline)
library(webshot)
library(htmlwidgets)
library(formattable)
library(here)
library(lme4)
library(lmerTest)
library(rstatix)
library(papeR)
library(knitr)
library(waffle)
library(ggsankey)
library(dplyr)
library(tidyverse)
load(here("anonymized_data/final_merged_data.Rda"))
load(here("anonymized_data/final_data_no_exc.Rda"))
load(here("anonymized_data/final_data_strat.Rda"))
load(here("anonymized_data/longitudinal_data.Rda"))
#Saving my palette to use in visualizations
my_yellow<-"#FFC107"
my_orange<- "#D95F02"
my_blue<- "#1F78B4"
my_green<- "#33a02c"
my_purple<- "#7570b3"
View(final_data_strat)
#Calculating how many families use each strategy and its corresponding %
prop_strategy<- first_visit_only %>%
group_by(strategy) %>%
tally() %>%
mutate(prop = n/sum(n)) %>%
mutate(perc= prop*100)
library(lubridate)
library(sparkline)
library(webshot)
library(htmlwidgets)
library(formattable)
library(here)
library(lme4)
library(lmerTest)
library(rstatix)
library(papeR)
library(knitr)
library(waffle)
library(ggsankey)
library(dplyr)
library(tidyverse)
load(here("anonymized_data/final_merged_data.Rda"))
load(here("anonymized_data/final_data_no_exc.Rda"))
load(here("anonymized_data/final_data_strat.Rda"))
load(here("anonymized_data/longitudinal_data.Rda"))
#Saving my palette to use in visualizations
my_yellow<-"#FFC107"
my_orange<- "#D95F02"
my_blue<- "#1F78B4"
my_green<- "#33a02c"
my_purple<- "#7570b3"
#### CONSTRUCTING AND DESCRIBING ALL RELEVANT DATA SETS ####
#Exclusions count
total_excluded<- final_data_no_exc %>%
group_by(unique_id, exp_l1, exp_l2)%>%
mutate(total_l1_l2_exp=(sum(exp_l1,exp_l2,na.rm = T))) %>%
ungroup() %>%
filter(total_l1_l2_exp<=90) %>%
distinct(unique_id)%>%
tally()
#after third language exclusions exclusions
n <- final_data %>%
distinct(unique_id) %>%
tally()
#subseting to get data only from each child's first visit to the lab. For main analyses
first_visit_only <- final_data_strat%>%
arrange(anon_baby_id, age) %>%
group_by(anon_baby_id) %>%
mutate(visit = row_number()) %>%
ungroup() %>%
filter(visit==1) #439 data from first visit only
#n when only taking first visit
n_keep_first_visit<-first_visit_only %>%
distinct(unique_id)%>%
tally()
age_min <- round(min(first_visit_only$age, na.rm = T), 2)
age_max<- round(max(first_visit_only$age, na.rm = T), 2)
age_mean<- round(mean(first_visit_only$age, na.rm = T), 2)
age_sd<- round(sd(first_visit_only$age, na.rm = T), 2)
female<- first_visit_only %>%
filter(gender=="female")%>%
distinct(unique_id)%>%
tally()
twice_visit <- final_data %>%
add_count(anon_baby_id) %>%
filter(nn==2)%>%
distinct(unique_id)%>%
tally()
three_visit <- final_data %>%
add_count(anon_baby_id) %>%
filter(nn==3)%>%
distinct(unique_id)%>%
tally()
four_visit <- final_data %>%
add_count(anon_baby_id) %>%
filter(nn>3)%>%
distinct(unique_id)%>%
tally()
#l1 percentages
l1_perc <- first_visit_only %>%
group_by(l1) %>%
tally() %>%
mutate(prop = n/sum(n)) %>%
mutate(perc= prop*100)
fre_l1 <- l1_perc %>%
filter(l1=="French") %>%
select(perc)
eng_l1 <- l1_perc %>%
filter(l1=="English") %>%
select(perc)
min_l1<- abs(fre_l1-eng_l1)
#l2 percentages
l2_perc <- first_visit_only %>%
group_by(l2) %>%
tally() %>%
mutate(prop = n/sum(n)) %>%
mutate(perc= prop*100)
fre_l2 <- l2_perc %>%
filter(l2=="French") %>%
select(perc)
eng_l2 <- l2_perc %>%
filter(l2=="English") %>%
select(perc)
min_l2<- abs(fre_l2-eng_l2)
#l1 amount of exposure range
min_exp_range <- final_data %>%
select(exp_l1) %>%
min()
max_exp_range <-final_data %>%
select(exp_l1) %>%
max()
#Prepping longitudinal data excluding irrelevant cases
longitudinal_data_analyses <- longitudinal_data %>%
select(age, strategy, unique_id, anon_baby_id, leq_date)
longitudinal_data_analyses <- longitudinal_data %>%
arrange(anon_baby_id, age) %>%
group_by(anon_baby_id) %>%
mutate(visit = row_number()) %>%
ungroup() %>%
mutate(first_visit_date = case_when(visit == 1 ~ leq_date)) %>%
mutate(second_visit_date = case_when(visit == 2 ~ leq_date)) %>%
group_by(anon_baby_id) %>%
fill(first_visit_date, second_visit_date, .direction="updown") %>% #to collapse the rows and be able to calculate visit
ungroup() %>%
mutate(length_between_visits = abs(interval(start= first_visit_date, end=second_visit_date)/ duration (n=1, unit="days" ))) %>%
filter(! length_between_visits < 15)
#Longitudinal data set n
n_long <-longitudinal_data_analyses %>%
distinct(unique_id)%>%
tally()
#Longitudinal data set length between visit one and 2
visit_length<- longitudinal_data %>%
arrange(anon_baby_id, age) %>%
group_by(anon_baby_id) %>%
mutate(visit = row_number()) %>%
ungroup() %>%
filter(nn==2) %>%
mutate(first_visit_date = case_when(visit == 1 ~ leq_date)) %>%
mutate(second_visit_date = case_when(visit == 2 ~ leq_date)) %>%
select(anon_baby_id, first_visit_date, second_visit_date) %>%
group_by(anon_baby_id) %>%
fill(first_visit_date, second_visit_date, .direction="updown") %>% #to collapse the rows and be able to calculate visit
distinct() %>%
ungroup() %>%
mutate(length_between_visits = abs(interval(start= first_visit_date, end=second_visit_date)/ duration (n=1, unit="days" ))) %>%
filter(! length_between_visits < 15) ##Filter visits that were very close together.
##!! There is a mistake in one date which results in a negative date. Fix.
avg_visit_l <- round(mean(visit_length$length_between_visits), 2)
min_visit_l <- round(min(visit_length$length_between_visits),2)
max_visit_l <- round(max(visit_length$length_between_visits),2)
sd_visit_l <- round(sd(visit_length$length_between_visits),2)
#Calculating how many families use each strategy and its corresponding %
prop_strategy<- first_visit_only %>%
group_by(strategy) %>%
tally() %>%
mutate(prop = n/sum(n)) %>%
mutate(perc= prop*100)
View(prop_strategy)
fre_by_strategy <- first_visit_only  %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(fre_exp)) %>%
arrange(desc("mean(fre_exp)"))
View(fre_by_strategy)
fre_by_strategy <- first_visit_only  %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(fre_exp), na.rm=T) %>%
arrange(desc("mean(fre_exp)"))
View(fre_by_strategy)
fre_by_strategy <- first_visit_only  %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(fre_exp,  na.rm=TRUE)) %>%
arrange(desc("mean(fre_exp)"))
View(fre_by_strategy)
library(lubridate)
library(sparkline)
library(webshot)
library(htmlwidgets)
library(formattable)
library(here)
library(lme4)
library(lmerTest)
library(rstatix)
library(papeR)
library(knitr)
library(waffle)
library(ggsankey)
library(dplyr)
library(tidyverse)
load(here("anonymized_data/final_merged_data.Rda"))
load(here("anonymized_data/final_data_no_exc.Rda"))
load(here("anonymized_data/final_data_strat.Rda"))
load(here("anonymized_data/longitudinal_data.Rda"))
#Saving my palette to use in visualizations
my_yellow<-"#FFC107"
my_orange<- "#D95F02"
my_blue<- "#1F78B4"
my_green<- "#33a02c"
my_purple<- "#7570b3"
#### CONSTRUCTING AND DESCRIBING ALL RELEVANT DATA SETS ####
#Exclusions count
total_excluded<- final_data_no_exc %>%
group_by(unique_id, exp_l1, exp_l2)%>%
mutate(total_l1_l2_exp=(sum(exp_l1,exp_l2,na.rm = T))) %>%
ungroup() %>%
filter(total_l1_l2_exp<=90) %>%
distinct(unique_id)%>%
tally()
#after third language exclusions exclusions
n <- final_data %>%
distinct(unique_id) %>%
tally()
#subseting to get data only from each child's first visit to the lab. For main analyses
first_visit_only <- final_data_strat%>%
arrange(anon_baby_id, age) %>%
group_by(anon_baby_id) %>%
mutate(visit = row_number()) %>%
ungroup() %>%
filter(visit==1) #439 data from first visit only
#n when only taking first visit
n_keep_first_visit<-first_visit_only %>%
distinct(unique_id)%>%
tally()
age_min <- round(min(first_visit_only$age, na.rm = T), 2)
age_max<- round(max(first_visit_only$age, na.rm = T), 2)
age_mean<- round(mean(first_visit_only$age, na.rm = T), 2)
age_sd<- round(sd(first_visit_only$age, na.rm = T), 2)
female<- first_visit_only %>%
filter(gender=="female")%>%
distinct(unique_id)%>%
tally()
twice_visit <- final_data %>%
add_count(anon_baby_id) %>%
filter(nn==2)%>%
distinct(unique_id)%>%
tally()
three_visit <- final_data %>%
add_count(anon_baby_id) %>%
filter(nn==3)%>%
distinct(unique_id)%>%
tally()
four_visit <- final_data %>%
add_count(anon_baby_id) %>%
filter(nn>3)%>%
distinct(unique_id)%>%
tally()
#l1 percentages
l1_perc <- first_visit_only %>%
group_by(l1) %>%
tally() %>%
mutate(prop = n/sum(n)) %>%
mutate(perc= prop*100)
fre_l1 <- l1_perc %>%
filter(l1=="French") %>%
select(perc)
eng_l1 <- l1_perc %>%
filter(l1=="English") %>%
select(perc)
min_l1<- abs(fre_l1-eng_l1)
#l2 percentages
l2_perc <- first_visit_only %>%
group_by(l2) %>%
tally() %>%
mutate(prop = n/sum(n)) %>%
mutate(perc= prop*100)
fre_l2 <- l2_perc %>%
filter(l2=="French") %>%
select(perc)
eng_l2 <- l2_perc %>%
filter(l2=="English") %>%
select(perc)
min_l2<- abs(fre_l2-eng_l2)
#l1 amount of exposure range
min_exp_range <- final_data %>%
select(exp_l1) %>%
min()
max_exp_range <-final_data %>%
select(exp_l1) %>%
max()
#Prepping longitudinal data excluding irrelevant cases
longitudinal_data_analyses <- longitudinal_data %>%
select(age, strategy, unique_id, anon_baby_id, leq_date)
longitudinal_data_analyses <- longitudinal_data %>%
arrange(anon_baby_id, age) %>%
group_by(anon_baby_id) %>%
mutate(visit = row_number()) %>%
ungroup() %>%
mutate(first_visit_date = case_when(visit == 1 ~ leq_date)) %>%
mutate(second_visit_date = case_when(visit == 2 ~ leq_date)) %>%
group_by(anon_baby_id) %>%
fill(first_visit_date, second_visit_date, .direction="updown") %>% #to collapse the rows and be able to calculate visit
ungroup() %>%
mutate(length_between_visits = abs(interval(start= first_visit_date, end=second_visit_date)/ duration (n=1, unit="days" ))) %>%
filter(! length_between_visits < 15)
#Longitudinal data set n
n_long <-longitudinal_data_analyses %>%
distinct(unique_id)%>%
tally()
#Longitudinal data set length between visit one and 2
visit_length<- longitudinal_data %>%
arrange(anon_baby_id, age) %>%
group_by(anon_baby_id) %>%
mutate(visit = row_number()) %>%
ungroup() %>%
filter(nn==2) %>%
mutate(first_visit_date = case_when(visit == 1 ~ leq_date)) %>%
mutate(second_visit_date = case_when(visit == 2 ~ leq_date)) %>%
select(anon_baby_id, first_visit_date, second_visit_date) %>%
group_by(anon_baby_id) %>%
fill(first_visit_date, second_visit_date, .direction="updown") %>% #to collapse the rows and be able to calculate visit
distinct() %>%
ungroup() %>%
mutate(length_between_visits = abs(interval(start= first_visit_date, end=second_visit_date)/ duration (n=1, unit="days" ))) %>%
filter(! length_between_visits < 15) ##Filter visits that were very close together.
##!! There is a mistake in one date which results in a negative date. Fix.
avg_visit_l <- round(mean(visit_length$length_between_visits), 2)
min_visit_l <- round(min(visit_length$length_between_visits),2)
max_visit_l <- round(max(visit_length$length_between_visits),2)
sd_visit_l <- round(sd(visit_length$length_between_visits),2)
fre_by_strategy <- first_visit_only  %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(fre_exp,  na.rm=TRUE)) %>%
arrange(desc("mean(fre_exp)"))
View(fre_by_strategy)
?rename
fre_by_strategy <- first_visit_only  %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(fre_exp,  na.rm=TRUE)) %>%
arrange(desc("mean(fre_exp,  na.rm=TRUE)")) %>%
mutate(rename(mean_fre_exp= mean(fre_exp,  na.rm=TRUE)))
fre_by_strategy <- first_visit_only  %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(fre_exp,  na.rm=TRUE)) %>%
mutate(rename(mean_fre_exp= mean(fre_exp,  na.rm=TRUE) ))
View(fre_by_strategy)
fre_by_strategy <- first_visit_only  %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(fre_exp,  na.rm=TRUE)) %>%
mutate(rename("mean_fre_exp"= "mean(fre_exp, na.rm=TRUE)"))
fre_by_strategy <- first_visit_only  %>%
select(c(strategy, fre_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(fre_exp,  na.rm=TRUE)) %>%
arrange(desc("mean(fre_exp, na.rm=TRUE)"))
rename(fre_by_strategy, mean_fre_exp = mean(fre_exp, na.rm=TRUE))
rename(fre_by_strategy, "mean_fre_exp" = "mean(fre_exp, na.rm=TRUE)")
str(fre_by_strategy)
rename(fre_by_strategy, "mean_fre_exp" = "mean(fre_exp, na.rm = TRUE)")
View(fre_by_strategy)
fre_by_strategy<- rename(fre_by_strategy, "mean_fre_exp" = "mean(fre_exp, na.rm = TRUE)")
View(fre_by_strategy)
eng_by_strategy <- first_visit_only  %>%
select(c(strategy, eng_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(eng_exp, na.rm=TRUE))%>%
arrange(desc("mean(eng_exp, na.rm=TRUE)"))
eng_by_strategy <- rename(eng_by_strategy, "mean_eng_exp" = "mean(eng_exp, na.rm=TRUE)")
str(eng_by_strategy)
eng_by_strategy <- rename(eng_by_strategy, "mean_eng_exp" = "mean(eng_exp, na.rm = TRUE)")
min_by_strategy <- first_visit_only  %>%
select(c(strategy, min_exp)) %>%
group_by(strategy) %>%
dplyr::summarize(mean(min_exp, na.rm=TRUE)) %>%
arrange(desc("mean(min_exp)"))
str(min_by_strategy)
min_by_strategy <- rename(min_by_strategy, "mean_heritage_exp" = "mean(min_exp, na.rm = TRUE)")
